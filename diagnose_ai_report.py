#!/usr/bin/env python3
# =============================================================================
# diagnose_ai_report.py - AIæŠ¥å‘Šç”Ÿæˆè¯Šæ–­å·¥å…·
#
# ä½¿ç”¨æ–¹æ³•ï¼š
# python diagnose_ai_report.py <å›¾ç‰‡è·¯å¾„>
#
# åŠŸèƒ½ï¼š
# 1. æµ‹è¯•ä¸åŒçš„é‡‡æ ·å‚æ•°
# 2. ç”Ÿæˆå¤šä¸ªæŠ¥å‘Šæ ·æœ¬
# 3. æ˜¾ç¤ºè¯¦ç»†çš„è°ƒè¯•ä¿¡æ¯
# =============================================================================

import sys
import os

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from config import Config
from inference_engine.engine import MedicalReportEngine


def test_sampling_strategies(engine, image_path):
    """æµ‹è¯•ä¸åŒçš„é‡‡æ ·ç­–ç•¥"""
    
    print("\n" + "="*80)
    print("ğŸ§ª æµ‹è¯•ä¸åŒçš„é‡‡æ ·ç­–ç•¥")
    print("="*80)
    
    strategies = [
        {
            'name': 'è´ªå©ªè§£ç ï¼ˆåŸå§‹æ–¹æ³•ï¼‰',
            'params': {'use_sampling': False}
        },
        {
            'name': 'æ¸©åº¦é‡‡æ · (T=0.7)',
            'params': {'temperature': 0.7, 'top_k': 0, 'top_p': 0.0, 'use_sampling': True}
        },
        {
            'name': 'æ¸©åº¦é‡‡æ · (T=1.0)',
            'params': {'temperature': 1.0, 'top_k': 0, 'top_p': 0.0, 'use_sampling': True}
        },
        {
            'name': 'Top-Ké‡‡æ · (K=30)',
            'params': {'temperature': 0.8, 'top_k': 30, 'top_p': 0.0, 'use_sampling': True}
        },
        {
            'name': 'Top-Pé‡‡æ · (P=0.9)',
            'params': {'temperature': 0.8, 'top_k': 0, 'top_p': 0.9, 'use_sampling': True}
        },
        {
            'name': 'Top-K + Top-Pç»„åˆï¼ˆæ¨èï¼‰',
            'params': {'temperature': 0.8, 'top_k': 50, 'top_p': 0.9, 'use_sampling': True}
        },
    ]
    
    for strategy in strategies:
        print(f"\nğŸ“Š ç­–ç•¥: {strategy['name']}")
        print("-" * 80)
        report = engine.generate(image_path, **strategy['params'])
        print(f"æŠ¥å‘Š: {report}")


def generate_multiple_samples(engine, image_path, num_samples=5):
    """ç”Ÿæˆå¤šä¸ªæ ·æœ¬ä»¥æ£€æŸ¥å¤šæ ·æ€§"""
    
    print("\n" + "="*80)
    print(f"ğŸ² ç”Ÿæˆ {num_samples} ä¸ªä¸åŒçš„æŠ¥å‘Šæ ·æœ¬")
    print("="*80)
    
    reports = engine.generate_multiple(
        image_path, 
        num_samples=num_samples,
        temperature=0.8,
        top_k=50,
        top_p=0.9
    )
    
    print("\nç”Ÿæˆçš„æŠ¥å‘Šï¼š")
    for i, report in enumerate(reports, 1):
        print(f"\næ ·æœ¬ {i}:")
        print(f"  {report}")
    
    # æ£€æŸ¥å”¯ä¸€æ€§
    unique_reports = set(reports)
    print(f"\nğŸ“ˆ ç»Ÿè®¡ä¿¡æ¯:")
    print(f"  æ€»æ ·æœ¬æ•°: {len(reports)}")
    print(f"  å”¯ä¸€æŠ¥å‘Šæ•°: {len(unique_reports)}")
    print(f"  å¤šæ ·æ€§: {len(unique_reports)/len(reports)*100:.1f}%")
    
    if len(unique_reports) == 1:
        print("\nâš ï¸  è­¦å‘Š: æ‰€æœ‰ç”Ÿæˆçš„æŠ¥å‘Šéƒ½ç›¸åŒï¼")
        print("   å¯èƒ½çš„åŸå› :")
        print("   1. æ¨¡å‹è¿‡æ‹Ÿåˆï¼Œå­¦ä¹ åˆ°äº†å›ºå®šçš„æ¨¡æ¿")
        print("   2. æ¨¡å‹æƒé‡å¯èƒ½æ²¡æœ‰æ­£ç¡®åŠ è½½")
        print("   3. å›¾åƒé¢„å¤„ç†å¯èƒ½æœ‰é—®é¢˜")
    elif len(unique_reports) < len(reports) * 0.5:
        print("\nâš ï¸  è­¦å‘Š: æŠ¥å‘Šå¤šæ ·æ€§è¾ƒä½")
    else:
        print("\nâœ… æŠ¥å‘Šå¤šæ ·æ€§æ­£å¸¸")


def main():
    if len(sys.argv) < 2:
        print("ä½¿ç”¨æ–¹æ³•: python diagnose_ai_report.py <å›¾ç‰‡è·¯å¾„>")
        sys.exit(1)
    
    image_path = sys.argv[1]
    
    if not os.path.exists(image_path):
        print(f"âŒ é”™è¯¯: å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨: {image_path}")
        sys.exit(1)
    
    print("ğŸ”§ åˆå§‹åŒ–è¯Šæ–­å·¥å…·...")
    print(f"ğŸ“ å›¾ç‰‡è·¯å¾„: {image_path}")
    
    # æ„å»ºé…ç½®
    config = Config()
    engine_config = {
        'MODEL_PATH': config.MODEL_PATH,
        'VOCAB_PATH': config.VOCAB_PATH,
        'IMG_SIZE': config.IMG_SIZE,
        'IMG_MEAN': config.IMG_MEAN,
        'IMG_STD': config.IMG_STD,
        'VOCAB_SIZE': config.VOCAB_SIZE,
        'CNN_OUT_FEATURES': config.CNN_OUT_FEATURES,
        'LSTM_HIDDEN_SIZE': config.LSTM_HIDDEN_SIZE,
        'LSTM_NUM_LAYERS': config.LSTM_NUM_LAYERS,
        'LSTM_DROPOUT': config.LSTM_DROPOUT,
        'MAX_REPORT_LEN': config.MAX_REPORT_LEN,
        'PAD_TOKEN_ID': config.PAD_TOKEN_ID,
        'SOS_TOKEN_ID': config.SOS_TOKEN_ID,
        'EOS_TOKEN_ID': config.EOS_TOKEN_ID,
    }
    
    # åˆ›å»ºå¼•æ“ï¼ˆå¯ç”¨è°ƒè¯•æ¨¡å¼ï¼‰
    engine = MedicalReportEngine(config_dict=engine_config, debug=True)
    
    if engine.model is None or engine.vocab is None:
        print("âŒ é”™è¯¯: æ¨¡å‹æˆ–è¯æ±‡è¡¨æœªèƒ½æ­£ç¡®åŠ è½½")
        sys.exit(1)
    
    # è¿è¡Œè¯Šæ–­æµ‹è¯•
    test_sampling_strategies(engine, image_path)
    generate_multiple_samples(engine, image_path, num_samples=5)
    
    print("\n" + "="*80)
    print("âœ… è¯Šæ–­å®Œæˆï¼")
    print("="*80)
    
    print("\nğŸ’¡ å»ºè®®ï¼š")
    print("1. å¦‚æœæ‰€æœ‰æ–¹æ³•éƒ½ç”Ÿæˆç›¸åŒçš„æŠ¥å‘Šï¼Œé—®é¢˜å¯èƒ½åœ¨äºæ¨¡å‹æœ¬èº«")
    print("2. å¦‚æœé‡‡æ ·æ–¹æ³•ç”Ÿæˆäº†ä¸åŒçš„æŠ¥å‘Šï¼Œå¯ä»¥åœ¨app.pyä¸­è°ƒæ•´é‡‡æ ·å‚æ•°")
    print("3. æ¨èä½¿ç”¨ temperature=0.8, top_k=50, top_p=0.9 çš„ç»„åˆ")


if __name__ == '__main__':
    main()
