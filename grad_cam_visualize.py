# ========================================================================
# grad_cam_visualize.py - ä¸ºä½ çš„åŒ»ç–—æŠ¥å‘Šç”Ÿæˆæ¨¡å‹ç”Ÿæˆ Grad-CAM çƒ­åŠ›å›¾
# é€‚é…æ¨¡å‹: ResNet18 + LSTM (æ¥è‡ª model_definition.py)
# ä¿®æ­£ï¼šæ”¯æŒ CUDA + LSTM åå‘ä¼ æ’­ï¼Œè‡ªåŠ¨ç®¡ç† model.train()/eval() æ¨¡å¼
# ========================================================================
import os
import sys
import torch
import torch.nn.functional as F
from PIL import Image
import numpy as np
import cv2
import matplotlib.pyplot as plt

# æ·»åŠ é¡¹ç›®è·¯å¾„ä»¥ä¾¿å¯¼å…¥æœ¬åœ°æ¨¡å—
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from config import Config
from inference_engine.engine import MedicalReportEngine


class GradCAM:
    """Grad-CAM å®ç°ï¼Œé€‚é… ResNet-based åŒ»ç–—å›¾åƒæè¿°æ¨¡å‹"""

    def __init__(self, model, target_layer):
        self.model = model
        self.target_layer = target_layer
        self.feature_maps = None
        self.gradients = None

        # æ³¨å†Œå‰å‘å’Œåå‘ hook
        self.target_layer.register_forward_hook(self.save_feature_maps)
        self.target_layer.register_full_backward_hook(self.save_gradients)

    def save_feature_maps(self, module, input, output):
        self.feature_maps = output.detach()

    def save_gradients(self, module, grad_in, grad_out):
        self.gradients = grad_out[0].detach()

    def __call__(self, image_tensor, sos_id, eos_id, max_len=20):
        """
        ç”Ÿæˆ Grad-CAM çƒ­åŠ›å›¾
        :param image_tensor: é¢„å¤„ç†åçš„å›¾åƒ [1, C, H, W]
        :param sos_id: å¼€å§‹ç¬¦ ID
        :param eos_id: ç»“æŸç¬¦ ID
        :param max_len: æœ€å¤§ç”Ÿæˆé•¿åº¦ï¼ˆæ§åˆ¶è®¡ç®—é‡ï¼‰
        :return: çƒ­åŠ›å›¾ numpy array [H, W]
        """
        # ä¿å­˜åŸå§‹æ¨¡å¼ï¼Œå¹¶å¼ºåˆ¶è¿›å…¥ train æ¨¡å¼ä»¥æ”¯æŒ LSTM backward
        was_training = self.model.training
        self.model.train()
        image_tensor.requires_grad_(True)

        try:
            with torch.enable_grad():
                # å‰å‘ï¼šè·å– CNN ç‰¹å¾
                cnn_features = self.model.encoder(image_tensor)  # [B, 256]

                # åˆå§‹åŒ– LSTM éšè—çŠ¶æ€
                h = self.model.decoder.init_h(cnn_features).unsqueeze(0).repeat(
                    self.model.decoder.num_layers, 1, 1
                )
                c = self.model.decoder.init_c(cnn_features).unsqueeze(0).repeat(
                    self.model.decoder.num_layers, 1, 1
                )

                # ç¬¬ä¸€ä¸ªè¾“å…¥ token: SOS
                input_ids = torch.full(
                    (1, 1), sos_id, dtype=torch.long, device=image_tensor.device
                )

                # æ‰§è¡Œä¸€æ­¥è§£ç ï¼ˆæˆ‘ä»¬åªå…³å¿ƒç¬¬ä¸€ä¸ªé¢„æµ‹è¯çš„æ¢¯åº¦ï¼‰
                embedded = self.model.decoder.embedding(input_ids)
                lstm_out, (h, c) = self.model.decoder.lstm(embedded, (h, c))
                logits = self.model.decoder.output_proj(lstm_out).squeeze(1)  # [1, vocab_size]

                # å¯¹ç¬¬ä¸€ä¸ªé¢„æµ‹è¯çš„æ‰€æœ‰ logit æ±‚å’Œï¼ˆå¾—åˆ° scalar ç”¨äº backwardï¼‰
                score = logits[0].sum()

                # æ¸…é›¶æ¢¯åº¦å¹¶åå‘ä¼ æ’­
                self.model.zero_grad()
                score.backward(retain_graph=False)

            # === è®¡ç®— Grad-CAM ===
            if self.gradients is None or self.feature_maps is None:
                raise RuntimeError("æœªèƒ½æ•è·æ¢¯åº¦æˆ–ç‰¹å¾å›¾ï¼Œè¯·æ£€æŸ¥ hook æ˜¯å¦æ³¨å†ŒæˆåŠŸ")

            gradients = self.gradients  # [1, 512, 7, 7]
            feature_maps = self.feature_maps  # [1, 512, 7, 7]

            # å…¨å±€å¹³å‡æ± åŒ–æ¢¯åº¦ â†’ æƒé‡ [512]
            weights = torch.mean(gradients, dim=[0, 2, 3])  # [512]

            # åŠ æƒæ±‚å’Œç‰¹å¾å›¾
            cam = torch.zeros(feature_maps.shape[2:], device=feature_maps.device)  # [7, 7]
            for i, w in enumerate(weights):
                cam += w * feature_maps[0, i, :, :]

            cam = F.relu(cam)
            cam = cam.cpu().numpy()
            cam = cv2.resize(cam, (image_tensor.shape[3], image_tensor.shape[2]))  # [224, 224]
            cam = cam - np.min(cam)
            cam = cam / (np.max(cam) + 1e-8)

            return cam

        finally:
            # æ¢å¤æ¨¡å‹åŸå§‹æ¨¡å¼
            if was_training:
                self.model.train()
            else:
                self.model.eval()


def preprocess_image(image_path, img_size=(224, 224), mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]):
    """ä¸ engine.py ä¸€è‡´çš„é¢„å¤„ç†æµç¨‹ï¼Œå¹¶è¿”å›åŒæ ·å°ºå¯¸çš„åŸå§‹å›¾åƒç”¨äºå¯è§†åŒ–"""
    from torchvision import transforms
    image = Image.open(image_path).convert('RGB')
    resized_image = image.resize(img_size, Image.Resampling.LANCZOS)
    original_for_overlay = np.array(resized_image)

    transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize(mean=mean, std=std)
    ])
    tensor = transform(resized_image).unsqueeze(0)
    return tensor, original_for_overlay


def overlay_heatmap(original_img, cam, alpha=0.6):
    """å°†çƒ­åŠ›å›¾å åŠ åˆ°åŸå›¾"""
    heatmap = cv2.applyColorMap(np.uint8(255 * cam), cv2.COLORMAP_JET)
    heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB)
    overlay = (alpha * heatmap + (1 - alpha) * original_img).astype(np.uint8)
    return overlay


def main():
    if len(sys.argv) < 2:
        print("ä½¿ç”¨æ–¹æ³•: python grad_cam_visualize.py <å›¾ç‰‡è·¯å¾„>")
        sys.exit(1)

    image_path = sys.argv[1]
    if not os.path.exists(image_path):
        print(f"é”™è¯¯: å›¾ç‰‡ä¸å­˜åœ¨ {image_path}")
        sys.exit(1)

    print(f"ğŸ–¼ï¸  åŠ è½½å›¾ç‰‡: {image_path}")

    # === åˆå§‹åŒ–å¼•æ“ï¼ˆä»…ç”¨äºåŠ è½½æ¨¡å‹ï¼‰===
    config = Config()
    engine_config = {
        'MODEL_PATH': config.MODEL_PATH,
        'VOCAB_PATH': config.VOCAB_PATH,
        'IMG_SIZE': config.IMG_SIZE,
        'IMG_MEAN': config.IMG_MEAN,
        'IMG_STD': config.IMG_STD,
        'VOCAB_SIZE': config.VOCAB_SIZE,
        'CNN_OUT_FEATURES': config.CNN_OUT_FEATURES,
        'LSTM_HIDDEN_SIZE': config.LSTM_HIDDEN_SIZE,
        'LSTM_NUM_LAYERS': config.LSTM_NUM_LAYERS,
        'LSTM_DROPOUT': config.LSTM_DROPOUT,
        'MAX_REPORT_LEN': config.MAX_REPORT_LEN,
        'PAD_TOKEN_ID': config.PAD_TOKEN_ID,
        'SOS_TOKEN_ID': config.SOS_TOKEN_ID,
        'EOS_TOKEN_ID': config.EOS_TOKEN_ID,
    }

    engine = MedicalReportEngine(config_dict=engine_config, debug=True)
    model = engine.model

    if model is None:
        print("âŒ æ¨¡å‹åŠ è½½å¤±è´¥")
        sys.exit(1)

    # === è·å– ResNet çš„ layer4 æ¨¡å—ï¼ˆç´¢å¼• 7ï¼‰===
    target_layer = model.encoder.features[7]  # resnet.layer4
    print(f"ğŸ¯ Hook ç›®æ ‡å±‚: model.encoder.features[7] (ResNet layer4)")

    # === é¢„å¤„ç†å›¾åƒ ===
    input_tensor, original_img = preprocess_image(
        image_path,
        img_size=config.IMG_SIZE,
        mean=config.IMG_MEAN,
        std=config.IMG_STD
    )
    input_tensor = input_tensor.to(engine.device)

    # === ç”Ÿæˆ Grad-CAM ===
    grad_cam = GradCAM(model, target_layer)
    cam = grad_cam(
        input_tensor,
        sos_id=config.SOS_TOKEN_ID,
        eos_id=config.EOS_TOKEN_ID,
        max_len=10
    )

    # === å åŠ çƒ­åŠ›å›¾ ===
    overlay = overlay_heatmap(original_img, cam)

    # === ä¿å­˜ç»“æœ ===
    base_name = os.path.splitext(os.path.basename(image_path))[0]
    output_path = f"gradcam_{base_name}.png"
    plt.figure(figsize=(12, 4))

    plt.subplot(1, 3, 1)
    plt.imshow(original_img)
    plt.title("Original Image")
    plt.axis('off')

    plt.subplot(1, 3, 2)
    plt.imshow(cam, cmap='jet')
    plt.title("Grad-CAM Heatmap")
    plt.axis('off')

    plt.subplot(1, 3, 3)
    plt.imshow(overlay)
    plt.title("Overlay")
    plt.axis('off')

    plt.tight_layout()
    plt.savefig(output_path, dpi=150, bbox_inches='tight')
    print(f"âœ… Grad-CAM ç»“æœå·²ä¿å­˜è‡³: {output_path}")

    # === åŒæ—¶ç”Ÿæˆ AI æŠ¥å‘Šç”¨äºå¯¹æ¯” ===
    report = engine.generate(image_path)
    print(f"\nğŸ“ AI ç”ŸæˆæŠ¥å‘Š:\n{report}")


if __name__ == '__main__':
    main()