# =============================================================================
# inference_engine/engine.py â€” åŒ»ç–—æŠ¥å‘Šç”Ÿæˆå¼•æ“ï¼ˆåŒ¹é…è®­ç»ƒæ¨¡å‹ï¼‰
# =============================================================================

import os
import torch
import pickle
from PIL import Image
from torchvision import transforms

from .model_definition import IUReportGenerator


class MedicalReportEngine:
    """åŒ»ç–—æŠ¥å‘Šç”Ÿæˆå¼•æ“ï¼ˆåŒ¹é…è®­ç»ƒæ¨¡å‹ç‰ˆæœ¬ï¼‰"""

    def __init__(self, config_dict, debug=False):
        """
        åˆå§‹åŒ–å¼•æ“ã€‚
        :param config_dict: ä¸€ä¸ªåŒ…å«æ‰€æœ‰å¿…è¦é…ç½®é¡¹çš„å­—å…¸ã€‚
        :param debug: æ˜¯å¦å¯ç”¨è°ƒè¯•æ¨¡å¼
        """
        self.config = config_dict
        self.debug = debug
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        
        if self.debug:
            print(f"ğŸ”§ ä½¿ç”¨è®¾å¤‡: {self.device}")

        # å›¾åƒé¢„å¤„ç†
        img_size = self.config['IMG_SIZE']
        if isinstance(img_size, int):
            resize_args = (img_size, img_size)
        elif isinstance(img_size, (list, tuple)) and len(img_size) == 2:
            resize_args = tuple(img_size)
        else:
            raise ValueError(f"IMG_SIZE must be an int or a tuple/list of length 2. Got: {img_size}")

        self.transform = transforms.Compose([
            transforms.Resize(resize_args),
            transforms.ToTensor(),
            transforms.Normalize(mean=self.config['IMG_MEAN'], std=self.config['IMG_STD'])
        ])
        
        self.model = None
        self.vocab = None
        self._load_model_and_vocab()

    def _load_model_and_vocab(self):
        """åŠ è½½æ¨¡å‹æƒé‡å’Œè¯æ±‡è¡¨"""
        model_path = self.config['MODEL_PATH']
        vocab_path = self.config['VOCAB_PATH']

        if not os.path.exists(model_path) or not os.path.exists(vocab_path):
            self.model = None
            self.vocab = None
            print("âŒ è­¦å‘Š: æ¨¡å‹æˆ–è¯æ±‡è¡¨æ–‡ä»¶æœªæ‰¾åˆ°ï¼ŒAIæŠ¥å‘ŠåŠŸèƒ½å°†ä¸å¯ç”¨ã€‚")
            print(f"   æ¨¡å‹è·¯å¾„: {model_path}")
            print(f"   è¯æ±‡è¡¨è·¯å¾„: {vocab_path}")
            return

        # åŠ è½½è¯æ±‡è¡¨
        try:
            with open(vocab_path, 'rb') as f:
                self.vocab = pickle.load(f)
            
            if self.debug:
                print(f"ğŸ“š è¯æ±‡è¡¨åŠ è½½æˆåŠŸ")
                if isinstance(self.vocab, dict):
                    print(f"   è¯æ±‡è¡¨å¤§å°: {len(self.vocab.get('idx2word', {}))}")
        except Exception as e:
            print(f"âŒ è¯æ±‡è¡¨åŠ è½½å¤±è´¥: {str(e)}")
            self.vocab = None
            return

        # å®ä¾‹åŒ–æ¨¡å‹
        try:
            self.model = IUReportGenerator(
                vocab_size=self.config['VOCAB_SIZE'],
                use_disease_features=True
            )
            
            if self.debug:
                print(f"ğŸ“¦ æ¨¡å‹ç»“æ„åˆ›å»ºæˆåŠŸ")
            
            # åŠ è½½æƒé‡
            checkpoint = torch.load(model_path, map_location=self.device, weights_only=False)
            
            if self.debug:
                print(f"ğŸ“‚ æ£€æŸ¥ç‚¹åŠ è½½æˆåŠŸ")
                if isinstance(checkpoint, dict):
                    print(f"   æ£€æŸ¥ç‚¹é”®: {list(checkpoint.keys())}")
            
            # æå–state_dict
            if isinstance(checkpoint, dict) and 'model_state_dict' in checkpoint:
                state_dict = checkpoint['model_state_dict']
            else:
                state_dict = checkpoint
            
            # åŠ è½½state_dict
            self.model.load_state_dict(state_dict, strict=True)
            self.model.to(self.device)
            self.model.eval()
            
            print("âœ… åŒ»ç–—æŠ¥å‘Šå¼•æ“åŠ è½½æˆåŠŸï¼")
            
        except Exception as e:
            print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}")
            import traceback
            if self.debug:
                traceback.print_exc()
            self.model = None
            return

    def generate(
        self, 
        image_path: str,
        temperature: float = 0.8,
        top_k: int = 50,
        top_p: float = 0.9,
        use_sampling: bool = True
    ) -> str:
        """
        è¾“å…¥å›¾åƒè·¯å¾„ï¼Œè¿”å›ç”Ÿæˆçš„æŠ¥å‘Šæ–‡æœ¬
        
        å‚æ•°è¯´æ˜ï¼š
        - temperature: æ¸©åº¦å‚æ•°ï¼ˆ0.7-1.0æ¨èï¼‰ï¼Œè¶Šé«˜è¶Šéšæœº
        - top_k: Top-Ké‡‡æ ·ï¼ˆ30-50æ¨èï¼‰ï¼Œé™åˆ¶å€™é€‰è¯æ•°é‡
        - top_p: Top-Pé‡‡æ ·ï¼ˆ0.85-0.95æ¨èï¼‰ï¼ŒNucleusé‡‡æ ·
        - use_sampling: æ˜¯å¦ä½¿ç”¨é‡‡æ ·ï¼ˆTrueæ¨èï¼ŒFalseåˆ™ä½¿ç”¨è´ªå©ªè§£ç ï¼‰
        """
        if self.model is None or self.vocab is None:
            return "AIæŠ¥å‘ŠåŠŸèƒ½æš‚ä¸å¯ç”¨ã€‚è¯·æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦æ­£ç¡®æ”¾ç½®ã€‚"

        try:
            # åŠ è½½å¹¶é¢„å¤„ç†å›¾åƒ
            image = Image.open(image_path).convert('RGB')
            tensor = self.transform(image).unsqueeze(0).to(self.device)
            
            if self.debug:
                print(f"ğŸ–¼ï¸  å›¾åƒå½¢çŠ¶: {tensor.shape}")
                print(f"ğŸ² ç”Ÿæˆå‚æ•°: temperature={temperature}, top_k={top_k}, top_p={top_p}, sampling={use_sampling}")

            # ç”ŸæˆæŠ¥å‘ŠIDåºåˆ—
            with torch.no_grad():
                output_ids = self.model.generate_report(
                    tensor,
                    sos_id=self.config['SOS_TOKEN_ID'],
                    eos_id=self.config['EOS_TOKEN_ID'],
                    max_len=self.config['MAX_REPORT_LEN'],
                    temperature=temperature,
                    top_k=top_k if top_k > 0 else None,
                    top_p=top_p if top_p > 0.0 else None,
                    use_sampling=use_sampling
                )
            
            if self.debug:
                print(f"ğŸ“ ç”Ÿæˆçš„token IDs (å‰20ä¸ª): {output_ids[0][:20].cpu().tolist()}")

            # å°†IDè½¬æ¢ä¸ºæ–‡æœ¬
            words = []
            token_ids = output_ids[0].cpu().numpy()
            
            # è·å–idx2wordæ˜ å°„
            if isinstance(self.vocab, dict):
                idx2word = self.vocab.get('idx2word', self.vocab)
            else:
                idx2word = self.vocab
            
            for idx in token_ids:
                if idx == self.config['EOS_TOKEN_ID']:
                    break
                if idx not in [self.config['PAD_TOKEN_ID'], self.config['SOS_TOKEN_ID']]:
                    word = idx2word.get(int(idx), '<unk>')
                    if word not in ['<UNK>', '<unk>', '<pad>', '<PAD>', '<SOS>', '<sos>', '<EOS>', '<eos>']:
                        words.append(word)
            
            if self.debug:
                print(f"ğŸ“„ ç”Ÿæˆçš„è¯è¯­: {words[:15]}...")

            # æ‹¼æ¥å¹¶æ ¼å¼åŒ–æŠ¥å‘Š
            report = " ".join(words).strip()
            
            # åŸºæœ¬çš„åå¤„ç†
            if report:
                # ç¡®ä¿å¥å­ä»¥å¥å·ç»“å°¾
                if not report.endswith('.'):
                    report += '.'
                # é¦–å­—æ¯å¤§å†™
                report = report[0].upper() + report[1:] if len(report) > 1 else report.upper()
            else:
                report = "No significant findings."
            
            if self.debug:
                print(f"âœ… æœ€ç»ˆæŠ¥å‘Š: {report}")
            
            return report

        except Exception as e:
            error_msg = f"ç”ŸæˆæŠ¥å‘Šæ—¶å‡ºé”™: {str(e)}"
            if self.debug:
                import traceback
                print(f"âŒ {error_msg}")
                traceback.print_exc()
            return error_msg
    
    def generate_multiple(
        self, 
        image_path: str, 
        num_samples: int = 3,
        temperature: float = 0.8,
        top_k: int = 50,
        top_p: float = 0.9
    ) -> list:
        """
        ä¸ºåŒä¸€å¼ å›¾ç‰‡ç”Ÿæˆå¤šä¸ªä¸åŒçš„æŠ¥å‘Š
        """
        reports = []
        for i in range(num_samples):
            if self.debug:
                print(f"\n--- ç”ŸæˆæŠ¥å‘Š #{i+1} ---")
            report = self.generate(
                image_path,
                temperature=temperature,
                top_k=top_k,
                top_p=top_p,
                use_sampling=True
            )
            reports.append(report)
        return reports
